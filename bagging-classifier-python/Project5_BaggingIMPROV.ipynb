{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging Classifier (from scratch) — Python\n",
    "\n",
    "This project implements **bagging (bootstrap aggregating)** for a small binary classification dataset using a **custom decision tree** learner and **majority voting**.\n",
    "\n",
    "**What’s included**\n",
    "- Bootstrap sampling (multiple rounds)\n",
    "- Decision tree training per round (custom splits)\n",
    "- Ensemble prediction via majority vote\n",
    "- Evaluation on a validation set (with analysis of results)\n",
    "\n",
    "> Note: The dataset is a small “toy” dataset used in a course exercise to demonstrate ensemble learning mechanics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e80de4d",
   "metadata": {},
   "source": [
    "## How to run\n",
    "\n",
    "1. Open the notebook in Jupyter (or Google Colab).\n",
    "2. Run cells top-to-bottom.\n",
    "3. Review the printed bootstrap samples, learned trees, and ensemble voting results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Bagging?\n",
    "\n",
    "Bagging means **Bootstrap Aggregating**. It is a way to combine several models so their predictions are more accurate.\n",
    "\n",
    "### The Problem Bagging Solves\n",
    "\n",
    "A single decision tree often fits the training data too closely. Even small changes in the data can create very different trees. Bagging helps by training several trees on different samples, which reduces this problem.\n",
    "\n",
    "### How Bagging Works\n",
    "\n",
    "1. **Bootstrap Sampling:** Randomly find N examples from the training data and allowing repeats.\n",
    "\n",
    "2. **Train Base Classifiers:** Build decision trees for each bootstrap sample. Each tree is built differently because it uses different data.\n",
    "\n",
    "3. **Aggregate Predictions:** Each tree votes for a class. The class with the most votes is the final prediction.\n",
    "\n",
    "### Why It Works\n",
    "\n",
    "By averaging the predictions from many trees, random mistakes tend to cancel out. Groups of trees tend to be more reliable at handling new data than just one tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:36.948048Z",
     "start_time": "2025-12-02T02:32:36.933208Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "- 3 binary attributes: A, B, and C, either 0 or 1.\n",
    "- 2 classes: + (positive) and - (negative).\n",
    "- 10 training instances, which are used to build the trees.\n",
    "- 5 validation instances, which are used to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.050775Z",
     "start_time": "2025-12-02T02:32:36.963222Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training data: [A, B, C, Class]\n",
    "TRAIN = [\n",
    "    [0, 0, 0, '+'],  # 1\n",
    "    [0, 0, 1, '+'],  # 2\n",
    "    [0, 1, 0, '+'],  # 3\n",
    "    [0, 1, 1, '-'],  # 4\n",
    "    [1, 0, 0, '+'],  # 5\n",
    "    [1, 0, 0, '+'],  # 6\n",
    "    [1, 1, 0, '-'],  # 7\n",
    "    [1, 0, 1, '+'],  # 8\n",
    "    [1, 1, 0, '-'],  # 9\n",
    "    [1, 1, 0, '-'],  # 10\n",
    "]\n",
    "\n",
    "# Validation data: [A, B, C, Class]\n",
    "VAL = [\n",
    "    [0, 0, 0, '+'],  # 11\n",
    "    [0, 1, 1, '+'],  # 12\n",
    "    [1, 1, 0, '+'],  # 13\n",
    "    [1, 0, 1, '-'],  # 14\n",
    "    [1, 0, 0, '+'],  # 15\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "A few helper functions are needed to handle common tasks before building trees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrap Sampling Function\n",
    "\n",
    "This function makes a bootstrap sample using the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.464066Z",
     "start_time": "2025-12-02T02:32:37.432076Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bootstrap_sample(data, seed):\n",
    "    \"\"\"Randomly pick rows with replacement\"\"\"\n",
    "    random.seed(seed)\n",
    "    n = len(data)\n",
    "    picked = []\n",
    "    for i in range(n):\n",
    "        picked.append(random.randint(0, n - 1))\n",
    "\n",
    "    sample = []\n",
    "    for i in picked:\n",
    "        sample.append(data[i])\n",
    "\n",
    "    return sample, picked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Function\n",
    "\n",
    "This function finds out how many positive (+) and negative (-) examples are in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.500895Z",
     "start_time": "2025-12-02T02:32:37.479022Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_plus_minus(data):\n",
    "    \"\"\"Count + and - in data\"\"\"\n",
    "    plus = 0\n",
    "    minus = 0\n",
    "    for row in data:\n",
    "        if row[3] == '+':\n",
    "            plus = plus + 1\n",
    "        else:\n",
    "            minus = minus + 1\n",
    "    return plus, minus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Majority Vote Function\n",
    "\n",
    "This function finds and returns the class that appears most often in a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.603977Z",
     "start_time": "2025-12-02T02:32:37.589269Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_majority(data):\n",
    "    \"\"\"Return most common class\"\"\"\n",
    "    plus, minus = count_plus_minus(data)\n",
    "    if plus >= minus:\n",
    "        return '+'\n",
    "    return '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Function\n",
    "\n",
    "This function divides the data according to a specific feature value.\n",
    "\n",
    "Decision trees split data based on feature values. This function divides the data into two groups: one where the feature is 0 and the other where it is 1, allowing for the building of the left and right subtrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.662712Z",
     "start_time": "2025-12-02T02:32:37.645259Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_by_feature(data, feat, val):\n",
    "    \"\"\"Get rows where feature equals value\"\"\"\n",
    "    result = []\n",
    "    for row in data:\n",
    "        if row[feat] == val:\n",
    "            result.append(row)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Decision Tree\n",
    "\n",
    "A decision tree sorts examples by asking questions about their features. Each step inside the tree checks one feature, and each end point gives a class prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.703824Z",
     "start_time": "2025-12-02T02:32:37.682685Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_tree(data, depth):\n",
    "    \"\"\"Build a simple decision tree\"\"\"\n",
    "    plus, minus = count_plus_minus(data)\n",
    "\n",
    "    # Stop if pure or too deep\n",
    "    if minus == 0:\n",
    "        return '+'\n",
    "    if plus == 0:\n",
    "        return '-'\n",
    "    if depth >= 3:\n",
    "        return get_majority(data)\n",
    "\n",
    "    # Find best feature (0=A, 1=B, 2=C)\n",
    "    best = None\n",
    "    best_score = -1\n",
    "\n",
    "    for feat in [0, 1, 2]:\n",
    "        left = split_by_feature(data, feat, 0)\n",
    "        right = split_by_feature(data, feat, 1)\n",
    "\n",
    "        if len(left) == 0 or len(right) == 0:\n",
    "            continue\n",
    "\n",
    "        # Score = how many correct\n",
    "        p0, m0 = count_plus_minus(left)\n",
    "        p1, m1 = count_plus_minus(right)\n",
    "        score = max(p0, m0) + max(p1, m1)\n",
    "\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best = feat\n",
    "\n",
    "    if best is None:\n",
    "        return get_majority(data)\n",
    "\n",
    "    # Build subtrees\n",
    "    left = split_by_feature(data, best, 0)\n",
    "    right = split_by_feature(data, best, 1)\n",
    "\n",
    "    return {\n",
    "        'feat': best,\n",
    "        0: build_tree(left, depth + 1),\n",
    "        1: build_tree(right, depth + 1)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction Function\n",
    "\n",
    "After building a tree, we use it to classify new instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.737683Z",
     "start_time": "2025-12-02T02:32:37.726165Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(tree, row):\n",
    "    \"\"\"Use tree to predict class\"\"\"\n",
    "    if tree == '+' or tree == '-':\n",
    "        return tree\n",
    "\n",
    "    feat = tree['feat']\n",
    "    val = row[feat]\n",
    "    return predict(tree[val], row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Printing Function\n",
    "\n",
    "This function prints the tree in a clear way, showing the if-then rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.770764Z",
     "start_time": "2025-12-02T02:32:37.761700Z"
    }
   },
   "outputs": [],
   "source": [
    "def print_tree(tree, indent=\"\"):\n",
    "    \"\"\"Print tree as rules\"\"\"\n",
    "    names = ['A', 'B', 'C']\n",
    "\n",
    "    if tree == '+' or tree == '-':\n",
    "        print(indent + \"=> \" + tree)\n",
    "        return\n",
    "\n",
    "    feat = tree['feat']\n",
    "    print(indent + names[feat] + \" = 0:\")\n",
    "    print_tree(tree[0], indent + \"  \")\n",
    "    print(indent + names[feat] + \" = 1:\")\n",
    "    print_tree(tree[1], indent + \"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display the Data\n",
    "\n",
    "The training and validation data from Figure 3.36."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.799874Z",
     "start_time": "2025-12-02T02:32:37.793175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA:\n",
      "Inst  A  B  C  Class\n",
      "-------------------------\n",
      "  1   0  0  0    +\n",
      "  2   0  0  1    +\n",
      "  3   0  1  0    +\n",
      "  4   0  1  1    -\n",
      "  5   1  0  0    +\n",
      "  6   1  0  0    +\n",
      "  7   1  1  0    -\n",
      "  8   1  0  1    +\n",
      "  9   1  1  0    -\n",
      " 10   1  1  0    -\n"
     ]
    }
   ],
   "source": [
    "print(\"TRAINING DATA:\")\n",
    "print(\"Inst  A  B  C  Class\")\n",
    "print(\"-\" * 25)\n",
    "for i in range(len(TRAIN)):\n",
    "    r = TRAIN[i]\n",
    "    print(str(i + 1).rjust(3) + \"   \" + str(r[0]) + \"  \" + str(r[1]) + \"  \" + str(r[2]) + \"    \" + r[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.861401Z",
     "start_time": "2025-12-02T02:32:37.848850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION DATA:\n",
      "Inst  A  B  C  Class\n",
      "-------------------------\n",
      " 11   0  0  0    +\n",
      " 12   0  1  1    +\n",
      " 13   1  1  0    +\n",
      " 14   1  0  1    -\n",
      " 15   1  0  0    +\n"
     ]
    }
   ],
   "source": [
    "print(\"VALIDATION DATA:\")\n",
    "print(\"Inst  A  B  C  Class\")\n",
    "print(\"-\" * 25)\n",
    "for i in range(len(VAL)):\n",
    "    r = VAL[i]\n",
    "    print(str(i + 11).rjust(3) + \"   \" + str(r[0]) + \"  \" + str(r[1]) + \"  \" + str(r[2]) + \"    \" + r[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging Rounds\n",
    "\n",
    "The bagging algorithm: create 5 decision trees, each trained on a different bootstrap sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:37.910009Z",
     "start_time": "2025-12-02T02:32:37.895544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAGGING ROUNDS\n",
      "==================================================\n",
      "\n",
      "--- Round 1 ---\n",
      "Bootstrap sample (instances): [1, 5, 3, 8, 6, 2, 8, 10, 8, 10]\n",
      "Tree 1:\n",
      "  B = 0:\n",
      "    => +\n",
      "  B = 1:\n",
      "    A = 0:\n",
      "      => +\n",
      "    A = 1:\n",
      "      => -\n",
      "\n",
      "--- Round 2 ---\n",
      "Bootstrap sample (instances): [7, 9, 9, 2, 3, 7, 4, 5, 1, 4]\n",
      "Tree 2:\n",
      "  B = 0:\n",
      "    => +\n",
      "  B = 1:\n",
      "    A = 0:\n",
      "      C = 0:\n",
      "        => +\n",
      "      C = 1:\n",
      "        => -\n",
      "    A = 1:\n",
      "      => -\n",
      "\n",
      "--- Round 3 ---\n",
      "Bootstrap sample (instances): [5, 7, 8, 5, 2, 5, 6, 1, 2, 8]\n",
      "Tree 3:\n",
      "  B = 0:\n",
      "    => +\n",
      "  B = 1:\n",
      "    => -\n",
      "\n",
      "--- Round 4 ---\n",
      "Bootstrap sample (instances): [2, 7, 1, 10, 10, 4, 9, 3, 10, 9]\n",
      "Tree 4:\n",
      "  A = 0:\n",
      "    B = 0:\n",
      "      => +\n",
      "    B = 1:\n",
      "      C = 0:\n",
      "        => +\n",
      "      C = 1:\n",
      "        => -\n",
      "  A = 1:\n",
      "    => -\n",
      "\n",
      "--- Round 5 ---\n",
      "Bootstrap sample (instances): [6, 2, 7, 9, 8, 10, 6, 5, 9, 7]\n",
      "Tree 5:\n",
      "  B = 0:\n",
      "    => +\n",
      "  B = 1:\n",
      "    => -\n"
     ]
    }
   ],
   "source": [
    "NUM_ROUNDS = 5\n",
    "trees = []\n",
    "\n",
    "print(\"BAGGING ROUNDS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for r in range(1, NUM_ROUNDS + 1):\n",
    "    print(\"\\n--- Round \" + str(r) + \" ---\")\n",
    "\n",
    "    # Get bootstrap sample\n",
    "    sample, picked = get_bootstrap_sample(TRAIN, seed=42 + r)\n",
    "\n",
    "    # Show which instances were picked\n",
    "    picked_nums = []\n",
    "    for p in picked:\n",
    "        picked_nums.append(p + 1)\n",
    "    print(\"Bootstrap sample (instances): \" + str(picked_nums))\n",
    "\n",
    "    # Build tree\n",
    "    tree = build_tree(sample, 0)\n",
    "    trees.append(tree)\n",
    "\n",
    "    # Show tree\n",
    "    print(\"Tree \" + str(r) + \":\")\n",
    "    print_tree(tree, \"  \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:38.011661Z",
     "start_time": "2025-12-02T02:32:37.984063Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions from each tree:\n",
      "--------------------------------------------------\n",
      "Round | I11 | I12 | I13 | I14 | I15 |\n",
      "  1   |  + |  + |  - |  + |  + |\n",
      "  2   |  + |  - |  - |  + |  + |\n",
      "  3   |  + |  - |  - |  + |  + |\n",
      "  4   |  + |  - |  - |  - |  - |\n",
      "  5   |  + |  - |  - |  + |  + |\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions from each tree:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# Store predictions\n",
    "all_preds = []\n",
    "for i in range(len(VAL)):\n",
    "    all_preds.append([])\n",
    "\n",
    "# Show each round's predictions\n",
    "header = \"Round |\"\n",
    "for i in range(len(VAL)):\n",
    "    header = header + \" I\" + str(i + 11) + \" |\"\n",
    "print(header)\n",
    "\n",
    "for r in range(NUM_ROUNDS):\n",
    "    line = \"  \" + str(r + 1) + \"   |\"\n",
    "    for v in range(len(VAL)):\n",
    "        pred = predict(trees[r], VAL[v])\n",
    "        all_preds[v].append(pred)\n",
    "        line = line + \"  \" + pred + \" |\"\n",
    "    print(line)\n",
    "\n",
    "print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-02T02:32:38.098273Z",
     "start_time": "2025-12-02T02:32:38.083066Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Results:\n",
      "--------------------------------------------------\n",
      "Instance 11: votes +5/-0 => + (true: +) CORRECT\n",
      "Instance 12: votes +1/-4 => - (true: +) WRONG\n",
      "Instance 13: votes +0/-5 => - (true: +) WRONG\n",
      "Instance 14: votes +4/-1 => + (true: -) WRONG\n",
      "Instance 15: votes +4/-1 => + (true: +) CORRECT\n",
      "\n",
      "==================================================\n",
      "ACCURACY: 2/5 = 40%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "print(\"Final Results:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for v in range(len(VAL)):\n",
    "    inst = VAL[v]\n",
    "    true_class = inst[3]\n",
    "\n",
    "    # Count votes\n",
    "    plus = 0\n",
    "    minus = 0\n",
    "    for p in all_preds[v]:\n",
    "        if p == '+':\n",
    "            plus = plus + 1\n",
    "        else:\n",
    "            minus = minus + 1\n",
    "\n",
    "    # Majority vote\n",
    "    if plus > minus:\n",
    "        final = '+'\n",
    "    else:\n",
    "        final = '-'\n",
    "\n",
    "    # Check if correct\n",
    "    if final == true_class:\n",
    "        result = \"CORRECT\"\n",
    "        correct = correct + 1\n",
    "    else:\n",
    "        result = \"WRONG\"\n",
    "\n",
    "    print(\"Instance \" + str(v + 11) + \": votes +\" + str(plus) + \"/-\" + str(minus) +\n",
    "          \" => \" + final + \" (true: \" + true_class + \") \" + result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ACCURACY: \" + str(correct) + \"/\" + str(len(VAL)) +\n",
    "      \" = \" + str(correct * 100 // len(VAL)) + \"%\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "- Implemented bagging with 5 decision trees\n",
    "- Each tree was trained on a bootstrap sample (10 instances sampled with replacement)\n",
    "- Combined predictions using majority voting\n",
    "\n",
    "### Results\n",
    "- Validation accuracy: 40% (2 out of 5 correct)\n",
    "\n",
    "### Why the Accuracy is Low\n",
    "\n",
    "The low accuracy is not surprising since the validation data has examples that do not match the patterns found in the training data.\n",
    "\n",
    "- **Instance 13** (A=1, B=1, C=0) is labeled **+** in validation, but in training, all examples with A=1 and B=1 are labeled **-** (instances 7, 9, 10). The model cannot learn to predict + for this pattern.\n",
    "\n",
    "- **Instance 14** (A=1, B=0, C=1) is labeled **-** in validation, but in training, instance 8 with the same features is labeled **+**.\n",
    "\n",
    "This shows that bagging can only learn from patterns present in the training data. It cannot fix differences between the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notes\n",
    "\n",
    "- This notebook was originally created for a course assignment and has been lightly cleaned for portfolio use.\n",
    "- The validation results are discussed in the analysis section; the dataset contains patterns that can limit achievable accuracy with this small setup.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
